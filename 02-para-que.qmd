# ¿Para qué investigamos? {#sec-para-que}

## La investigación como herramienta de transformación

Empecemos con una pregunta incómoda: ¿para qué investigas? Y no vale decir "porque me lo piden para graduarme". Eso es un requisito administrativo, no una razón.

La investigación en ciencias sociales existe para entender problemas reales y, ojalá, contribuir a resolverlos. No es decoración del CV. No es un trámite burocrático. Es una herramienta —probablemente la más poderosa que tenemos— para entender por qué las cosas son como son y cómo podrían ser diferentes.

El problema es que muchas veces la academia se desconecta de eso. Se produce conocimiento que nadie lee, que nadie usa, que nadie necesita. Papers que solo existen para engordar índices bibliométricos. Tesis que acumulan polvo en bibliotecas (o bytes en servidores). Y eso es un desperdicio enorme de talento, tiempo y recursos.

Bent Flyvbjerg lo dice sin anestesia en *Making Social Science Matter*: las ciencias sociales han fracasado en su intento de imitar a las ciencias naturales, produciendo conocimiento que rara vez importa fuera de los muros universitarios [@flyvbjerg2001]. Es una crítica dura. Pero tiene razón más veces de las que nos gustaría admitir.

¿Significa que toda investigación social es inútil? Por supuesto que no. Significa que necesitamos preguntarnos con honestidad *para qué* investigamos antes de empezar a hacerlo. Y esa pregunta —que parece obvia— es la que menos nos hacemos.

## La diferencia entre investigar y opinar con bibliografía

Aquí va una distinción crucial que muchos no entienden (o no quieren entender): investigar no es buscar evidencia que confirme lo que ya piensas. Eso es opinar con bibliografía. Y es sorprendentemente común.

Investigar es hacerte una pregunta genuina —una donde realmente no sabes la respuesta— y diseñar un proceso riguroso para encontrarla. Implica aceptar que podrías estar equivocado. Implica estar dispuesto a cambiar de opinión si la evidencia te lo exige.

¿Suena fácil? No lo es. Nuestro cerebro está diseñado para confirmar lo que ya creemos (se llama **sesgo de confirmación**, y es brutal). Daniel Kahneman dedicó décadas a demostrar que nuestro pensamiento está plagado de atajos mentales que nos llevan a conclusiones erróneas con una confianza injustificada [@kahneman2012]. Pero un buen investigador aprende a pelear contra sus propios sesgos. No los elimina —eso es imposible—, pero los reconoce y los controla.

Carl Sagan tenía una frase perfecta para esto: "Las afirmaciones extraordinarias requieren evidencia extraordinaria" [@sagan1997]. Simple. Demoledora. Y casi nadie la aplica.

Piensa en la última discusión política que tuviste (o que viste en Twitter). ¿Cuántas personas citaron evidencia real? ¿Y cuántas citaron evidencia *selectiva* que solo confirmaba lo que ya pensaban? Ahora piensa en cuántos papers académicos hacen esencialmente lo mismo, pero con citas a pie de página. Duele, ¿verdad?

## Investigación básica vs. aplicada: un falso dilema

No toda investigación tiene que resolver un problema inmediato. Hay una distinción clásica que vale la pena entender:

- **Investigación básica (o fundamental):** Busca generar conocimiento nuevo sin una aplicación práctica inmediata. ¿Por qué la gente vota como vota? ¿Cómo se forman las identidades colectivas? ¿Qué determina la confianza institucional?
- **Investigación aplicada:** Busca resolver un problema concreto. ¿Cómo reducir la deserción escolar en zonas rurales? ¿Qué política pública funciona mejor para reducir la pobreza? ¿Qué estrategia de comunicación mejora la adherencia a tratamientos de salud?

Ambas son valiosas. Ambas son necesarias. La básica alimenta a la aplicada (sin teoría, no hay soluciones informadas). Y la aplicada retroalimenta a la básica (los problemas reales generan nuevas preguntas teóricas).

Donald Stokes propuso una metáfora brillante para superar este falso dilema: el **cuadrante de Pasteur** [@stokes1997]. Louis Pasteur no hacía investigación "básica" ni "aplicada" en el sentido puro. Hacía ambas al mismo tiempo: buscaba entender los mecanismos fundamentales de la enfermedad *porque* quería curarla. Quería resolver un problema real *y* generar conocimiento fundamental. ¿Por qué no podemos hacer lo mismo en ciencias sociales?

| | Inspirada por el uso | No inspirada por el uso |
|---|---|---|
| **Busca entender** | Cuadrante de Pasteur (básica + aplicada) | Cuadrante de Bohr (básica pura) |
| **No busca entender** | Cuadrante de Edison (aplicada pura) | — |

El error es despreciar una u otra. El teórico que mira por encima del hombro al aplicado ("eso es consultoría, no ciencia") es tan miope como el aplicado que desprecia la teoría ("eso es filosofía, no sirve para nada"). Los problemas complejos de América Latina necesitan ambas miradas: la profundidad teórica para entender *por qué* ocurren las cosas y la orientación práctica para *cambiarlas*.

## Cuando la investigación cambia la realidad: ejemplos que importan

Para los que dicen que la investigación social "no sirve para nada", aquí van algunos contraejemplos demoledores:

### PROGRESA/Oportunidades (México)

En los años 90, el gobierno mexicano diseñó un programa de transferencias condicionadas para combatir la pobreza. Pero —y esto es lo extraordinario— lo diseñó *como un experimento.* De 506 comunidades elegibles, 320 fueron asignadas aleatoriamente a recibir el programa y 186 como grupo de control [@levy2006].

Los resultados mostraron mejoras significativas en matrícula escolar, nutrición y salud. Esos resultados —porque eran causalmente creíbles— convencieron a gobiernos de todo el mundo. Hoy, más de 60 países tienen programas de transferencias condicionadas inspirados en la evidencia de PROGRESA. Una investigación bien diseñada cambió la política social global.

### Escuela Nueva (Colombia)

En los años 70, Vicky Colbert diseñó un modelo educativo para escuelas rurales multigrado en Colombia. Durante décadas, la investigación empírica fue demostrando que los estudiantes de Escuela Nueva superaban a los de escuelas convencionales en logro académico *y* en competencias ciudadanas, incluso controlando por nivel socioeconómico. Esa evidencia permitió escalar el modelo a más de 20.000 escuelas y exportarlo a 16 países.

### La revolución de los microcréditos (y su desmitificación)

Muhammad Yunus ganó el Nobel de la Paz en 2006 por su trabajo con el Grameen Bank y los microcréditos. La narrativa era irresistible: pequeños préstamos que sacan a la gente de la pobreza. Pero cuando Banerjee, Duflo y otros hicieron evaluaciones rigurosas con experimentos aleatorios, encontraron que el efecto sobre la pobreza era modesto [@banerjee2007]. Los microcréditos ayudan, pero no son la bala de plata que se prometía.

¿Eso fue un fracaso de la investigación? Al contrario. Fue un éxito. La investigación hizo lo que debe hacer: separar lo que funciona de lo que solo suena bien. Sin esa evidencia, seguiríamos invirtiendo miles de millones en una intervención cuyo efecto no justifica la inversión.

::: {.callout-important}
## Reflexión

Los tres ejemplos anteriores tienen algo en común: la investigación no solo describió un problema, sino que generó evidencia que cambió decisiones concretas. Eso es lo que debería aspirar a hacer tu investigación, en la escala que sea.
:::

## La diferencia entre investigación y consultoría

Esta distinción importa mucho, especialmente en América Latina donde muchos investigadores combinan ambas actividades. Y no hay nada malo en eso —las consultorías pagan bien y generan experiencia real—, pero no son lo mismo.

| | Investigación | Consultoría |
|---|---|---|
| **Objetivo** | Generar conocimiento | Resolver un problema del cliente |
| **Pregunta** | Del investigador | Del cliente |
| **Método** | Elegido por rigor | Elegido por viabilidad y presupuesto |
| **Tiempo** | El que necesite | El que pague el contrato |
| **Producto** | Paper, tesis, libro | Informe con recomendaciones |
| **Audiencia** | Comunidad científica | El que paga |
| **Sesgo principal** | Confirmar tu teoría | Confirmar lo que el cliente quiere oír |

La diferencia más profunda es la relación con la verdad. En investigación, la verdad es el objetivo (al menos en principio). En consultoría, la verdad es deseable, pero a veces subordinada a la utilidad o —seamos honestos— a la satisfacción del cliente.

He visto consultorías donde los resultados "incómodos" desaparecen del informe final. Y he visto investigaciones donde los datos se masajean hasta que confirman la hipótesis del investigador. Ambas prácticas son deshonestas. Pero la presión es diferente: en la consultoría, la presión viene de afuera (el cliente). En la investigación, viene de adentro (tus propios sesgos y ambiciones).

¿Puedes hacer consultoría con rigor investigativo? Absolutamente. ¿Puedes investigar con la relevancia práctica de una buena consultoría? También. De hecho, las mejores investigaciones en ciencias sociales logran ambas cosas. Pero requiere honestidad sobre las tensiones entre ambos roles.

## "Publish or perish": la enfermedad de la academia moderna

No puedo hablar del "para qué" de la investigación sin hablar de la distorsión más grande del sistema: la presión por publicar.

La frase *publish or perish* (publica o perece) se ha convertido en el mantra de la academia moderna [@garfield1996]. Tu valor como académico se mide, cada vez más, por cuántos papers publicas, en qué revistas, y cuántas veces te citan. No por si tu investigación importa, si cambia algo, o si alguien la entiende.

Esto genera incentivos perversos:

- **Publicar cantidad sobre calidad.** Mejor 5 papers mediocres que uno bueno, porque los comités de evaluación cuentan artículos, no los leen.
- **Fragmentar resultados.** Un estudio que podría ser un paper sólido se convierte en tres papers delgados (la famosa "salami science": rebanar el salami lo más fino posible).
- **Sesgar hacia resultados "publicables".** Los resultados positivos y significativos se publican más fácilmente. Los resultados nulos (que encontraste que no hay efecto) van al cajón. Esto se llama **sesgo de publicación** y distorsiona todo lo que sabemos.
- **Investigar lo publicable, no lo importante.** Temas seguros, métodos populares, preguntas incrementales. Nadie arriesga una carrera en una pregunta audaz que puede no dar resultados.

¿Significa esto que publicar no importa? No. Publicar es la moneda de cambio de la ciencia. Es cómo compartimos conocimiento, cómo sometemos nuestras ideas al escrutinio de otros. El problema no es publicar; es que la presión por publicar ha dejado de ser un medio y se ha convertido en un fin en sí mismo.

Como dice Wayne Booth en *The Craft of Research*: "La investigación es un acto social. Investigamos para compartir con otros algo que no sabían" [@booth2016]. Esa es la razón de publicar. No tu índice h.

## ¿A quién le importa tu tesis?

Esta es quizás la pregunta más dura que tienes que hacerte. Y deberías hacértela temprano, no cuando ya llevas 6 meses escribiendo.

Tu investigación debería importarle a alguien más que a ti y a tu asesor. Debería tener una **audiencia** y una **relevancia** clara. Eso no significa que tiene que cambiar el mundo. Pero sí significa que debería poder responder a estas preguntas:

1. ¿Qué problema ayuda a entender o resolver?
2. ¿Quién se beneficia de este conocimiento?
3. ¿Qué aporta que no se sepa ya?

Si no puedes responder al menos dos de estas tres, probablemente necesitas repensar tu tema.

Umberto Eco, en su clásico *Cómo se hace una tesis*, tiene un consejo demoledor: una tesis no necesita ser genial, pero sí necesita ser **útil** para alguien que investigue después de ti [@eco2014]. Tu tesis es un ladrillo en un edificio. No necesita ser la piedra angular, pero tampoco puede ser un ladrillo suelto que no encaja en nada.

Piénsalo así: dentro de 5 años, ¿alguien que investigue tu tema va a encontrar tu tesis y va a decir "esto me sirvió"? Si la respuesta es sí, vas por buen camino. Si la respuesta es "nadie la va a encontrar porque el tema no le importa a nadie", tienes un problema que es mejor resolver ahora que después.

## El investigador como ciudadano: investigar con responsabilidad

Hay una dimensión que pocos manuales mencionan: la responsabilidad social del investigador. En América Latina investigamos en contextos de profunda desigualdad, violencia, exclusión y precariedad institucional. Eso no es un detalle; es el contexto que define las preguntas que hacemos y las respuestas que buscamos.

Investigar comunidades vulnerables y después desaparecer con los datos es una forma de extractivismo intelectual. Investigar un problema urgente y publicar los resultados 3 años después en una revista que nadie en esa comunidad va a leer es un desperdicio ético.

No digo que toda investigación deba ser "militante" o que no puedas estudiar cosas abstractas. Digo que hay que ser consciente de las implicaciones de lo que haces. Si entras a una comunidad, recoges sus historias, analizas sus problemas y te llevas todo sin devolver nada, hay algo que no funciona en tu modelo de investigación.

::: {.callout-tip}
## Ejercicio

Escribe en **una sola frase** para qué serviría tu investigación. No tres frases, no un párrafo: una frase. Si necesitas más de una frase, probablemente no tienes suficiente claridad todavía. Y eso está bien —para eso estamos aquí—, pero hay que trabajarlo.

Luego responde estas tres preguntas:

1. ¿Quién, concretamente, usaría los resultados de tu investigación? (No vale "la sociedad". ¿Qué persona, qué institución, qué programa?)
2. Si tu investigación no existiera, ¿qué se perdería?
3. ¿Tu investigación genera conocimiento nuevo o confirma lo que ya sabemos?

Si la respuesta a la pregunta 3 es "confirma lo que ya sabemos", no necesariamente es malo (la replicación es valiosa), pero necesitas ser honesto al respecto.
:::
